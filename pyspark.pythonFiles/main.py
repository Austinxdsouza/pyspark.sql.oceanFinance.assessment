import pyspark.sql
from pyspark.sql.functions import expr
from pyspark.sql.functions import when

if __name__ == '__main__':
    print("hi, Ocean Finance")

spark = pyspark.sql.SparkSession.builder.appName("oceanFinance").master("local[*]").getOrCreate()
#CREATE DATAFRAMES AND SQL TABLE
apps = spark.read.format("csv").option("header","true").option("inferSchema","true").load("resources_datasets/applications.csv")
apps.createTempView("apps")
loans = spark.read.format("csv").option("header","true").option("inferSchema","true").load("resources_datasets/loans.csv")
loans.createTempView("loans")
sources = spark.read.format("csv").option("header","true").option("inferSchema","true").load("resources_datasets/sources.csv")
sources.createTempView("sources")

#apps.printSchema()
#loans.printSchema()
#sources.printSchema()
#joined::CommandToJoin
join = spark.sql(" SELECT apps.app_id, apps.date,apps.description, \
                apps.status,sources.source_name, sources.daily_target, \
                loans.lender, loans.loan_name, loans.commission FROM  apps \
                      INNER JOIN sources ON apps.source_id = sources.source_id \
                      INNER JOIN loans ON apps.loan_id = loans.loan_id")
#join.createTempView("join")
joinOne = join.na.drop()
ExerciseNumberOne = joinOne.count()
print(f'EXERCISE ONE :: total count of credit applicants [approved, declined, submitted] from begining of time = {ExerciseNumberOne}')

#CountByStatus = joinOne.groupby("status").count()
#CountByStatus.createTempView("CountByStatus")
#spark.sql("SELECT status, count/4000 AS percentage FROM countbystatus").show()

#profitPercentOne = joinOne.withColumn("is_profit", expr("status == 'approved'")).withColumn("no_profit", expr("status == 'declined' || 'submitted'"))
profitPercentTwo = joinOne.withColumn("is_profit",  when(joinOne.status == "declined",0)
                                                    .when(joinOne.status == "approved",1)
                                                    .when(joinOne.status == "submitted",0))
profitPercentThree = profitPercentTwo.createTempView("profitPercentTwo")
print("EXERCISE TWO :: What is the average profit of all applications?")
ExcerciseNumberTwo = spark.sql("SELECT AVG(is_profit) as average_profit_percentage FROM profitPercentTwo").show()
loanSourcePivot = spark.sql("SELECT loan_name, daily_target,source_name FROM profitPercentTwo ")
print("EXERCISE THREE :: Which marketing sources are the first and second most popular for each loan type?")
loanSourcePivotOne = loanSourcePivot.groupby("loan_name").pivot("source_name").sum("daily_target").show()
print("EXERCISE FOUR :: Provide a list that shows for each day what is the percentage of profit generated by each marketing source and to what percentage did they reach their daily target")
percentProfitGenerated =  spark.sql("SELECT date,source_name, commission, count(app_id) as daily_applications, daily_target \
                                    FROM profitPercentTwo group by date,source_name, daily_target, commission  ")
percentProfitGenerated.createTempView("percentProfitGenerated")
spark.sql("select Date,source_name as Source, daily_applications * commission as profit, (daily_applications * commission )/daily_target * 100 as Daily_Target_percent \
          from percentProfitGenerated").show()





